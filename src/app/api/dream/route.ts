import { NextRequest, NextResponse } from 'next/server';

export const runtime = 'edge';

export async function POST(req: NextRequest) {
    try {
        const { dream } = await req.json();

        if (!dream) {
            return NextResponse.json({ error: "Dream text is required" }, { status: 400 });
        }

        const systemPrompt = `ë‹¹ì‹ ì€ 'ì¹¼ë¼ë¨¸ìŠ¤(Calamus)'ì˜ ì‹ ë¹„ë¡œìš´ AI ê¿ˆ í•´ëª½ê°€ì…ë‹ˆë‹¤. ìœµ ì‹¬ë¦¬í•™ê³¼ ê³ ì „ í•´ëª½í•™ì„ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤. ë§íˆ¬ëŠ” ì‹ ë¹„ë¡­ê³  ê³µê°ì ì´ë©° ì •ì¤‘í•œ 'í•´ìš”'ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”:
1. ğŸ”‘ **í•µì‹¬ ìƒì§•**: ê¿ˆì— ë‚˜ì˜¨ ì£¼ìš” ìƒì§• 3ê°€ì§€ì™€ ê·¸ ì˜ë¯¸
2. ğŸ§  **ì‹¬ë¦¬ì  ë©”ì‹œì§€**: ì´ ê¿ˆì´ ë³´ì—¬ì£¼ëŠ” ë‹¹ì‹ ì˜ ë‚´ë©´ ì‹¬ë¦¬ ìƒíƒœ
3. ğŸ”® **ë¯¸ë˜ì˜ ì•”ì‹œ**: ì•ìœ¼ë¡œ ì¼ì–´ë‚  ìˆ˜ ìˆëŠ” ì¼ì´ë‚˜ ì¡°ì–¸ (ê¸ì •ì  ë°©í–¥ ì œì‹œ)
4. âœ¨ **í–‰ìš´ì˜ ìš”ì†Œ**: ì´ ê¿ˆê³¼ ê´€ë ¨ëœ í–‰ìš´ì˜ ìƒ‰ê¹”ì´ë‚˜ ì•„ì´í…œ`;

        // Check if Cloudflare Gateway is configured (from .env)
        const accountId = process.env.CLOUDFLARE_ACCOUNT_ID;
        const gatewayName = process.env.CLOUDFLARE_GATEWAY_NAME || "calamus-ai-gateway";

        const openAiKey = process.env.OPENAI_API_KEY;

        if (accountId && gatewayName && openAiKey) {
            // Use Cloudflare Gateway
            const gatewayUrl = `https://gateway.ai.cloudflare.com/v1/${accountId}/${gatewayName}/openai/chat/completions`;

            const response = await fetch(gatewayUrl, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                    "Authorization": `Bearer ${openAiKey}`
                },
                body: JSON.stringify({
                    model: "gpt-4o-mini", // Use mini as per legacy code (server.py had gpt-4o-mini)
                    messages: [
                        { role: "system", content: systemPrompt },
                        { role: "user", content: `ê¿ˆ ë‚´ìš©: ${dream}` }
                    ],
                    temperature: 0.7
                })
            });

            const data = await response.json();
            if (!response.ok) throw new Error(JSON.stringify(data));
            return NextResponse.json({ result: data.choices[0].message.content });
        }
        else if (openAiKey) {
            // Direct OpenAI Fallback
            const response = await fetch("https://api.openai.com/v1/chat/completions", {
                method: "POST",
                headers: {
                    "Content-Type": "application/json",
                    "Authorization": `Bearer ${openAiKey}`
                },
                body: JSON.stringify({
                    model: "gpt-4o-mini",
                    messages: [
                        { role: "system", content: systemPrompt },
                        { role: "user", content: `ê¿ˆ ë‚´ìš©: ${dream}` }
                    ],
                    temperature: 0.7
                })
            });

            const data = await response.json();
            if (!response.ok) throw new Error(JSON.stringify(data));
            return NextResponse.json({ result: data.choices[0].message.content });
        }

        return NextResponse.json({ error: "Server Configuration Error: No AI Provider" }, { status: 500 });

    } catch (error: any) {
        console.error('Dream API Error:', error);
        return NextResponse.json({
            error: 'Failed to interpret dream',
            details: error.message || String(error),
            env_check: {
                hasOpenAi: !!process.env.OPENAI_API_KEY,
                hasAccountId: !!process.env.CLOUDFLARE_ACCOUNT_ID
            }
        }, { status: 500 });
    }
}
